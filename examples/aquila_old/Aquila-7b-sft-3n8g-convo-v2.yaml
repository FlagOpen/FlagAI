# comments
epochs: 1
batch_size: 16
gradient_accumulation_steps: 1
lr: 2.0e-5
warm_up: 0.03
#warm_up: 0.06
save_interval: 2000

weight_decay: 0.0
adam_beta1: 0.9
adam_beta2: 0.999

bmt_cpu_offload: False

bmt_pre_load: True

